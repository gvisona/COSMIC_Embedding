{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from disease_ontology import categorical_encoding, sorted_cancer_subtypes, map_histological_subtype, map_site_subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSMIC Data\n",
    "\n",
    "For this implementation of the somatic-mutation-based embeddings of COSMIC samples we used the v92 version of the Mutation Data (https://cancer.sanger.ac.uk/cosmic/download).\n",
    "The downloaded file is to be extracted in the same folder as this notebook.\n",
    "\n",
    "Due to the size of the dataset, it will be opened and parsed in with a streaming configuration, which will lead to the creation of temporary files that can be deleted afterwards. The limitations due to the size of the dataset will require multiple passes over the data, especially for the frequency related quality requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Choices\n",
    "\n",
    "The raw data downloaded from the COSMIC website consists of a tab separated file in which each line represents a single somatic mutation in a sample. Each sample presents multiple mutations, and each tumor from a specific patient may be used to extract multiple samples. The model implemented in the other files is used to embed each sample based on the somatic mutations profile described in the dataset, which is a vector that corresponds to the available list of somatic mutations where a value of 1 in component $j$ of the vector signals that a mutation of gene $j$ is present in the sample, and where a 0 represents the absence of that mutation.\n",
    "\n",
    "## Quality control\n",
    "\n",
    "The somatic mutations in the COSMIC dataset are filtered according to the following criteria:\n",
    "- labelled as \"Confirmed somatic variant\"\n",
    "- they must come from a genome-wide screen study\n",
    "- mapped onto the GRCh38 reference genome\n",
    "- the mutations must correspond to a gene (only coding mutations)\n",
    "- we exclude hypermutated samples (>1000 mutation) according to previous works in the literature (_Vogelstein, B., Papadopoulos, N., Velculescu, V. E., Zhou, S., Diaz, L. A., and Kinzler, K. W. (2013)._ Cancer genome landscapes)\n",
    "- underrepresented genes are removed (mutations that appear fewer than 100 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"tmp_data\"):\n",
    "    os.mkdir(\"tmp_data\")\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CosmicGenomeScreensMutantExport.tsv', header=0, sep='\\t', quotechar='\"', error_bad_lines=False, chunksize=10000)\n",
    "\n",
    "# First iteration through the data: filtering according to the qualitative requirements\n",
    "with open(\"tmp_data/cosmic_filtered_tmp.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i, chunk in tqdm(enumerate(df)):\n",
    "        chunk = chunk[(chunk[\"Mutation somatic status\"] == \"Confirmed somatic variant\") & (chunk[\"Genome-wide screen\"]== 'y')& \n",
    "                      (chunk[\"GRCh\"]==38) & \n",
    "                      (~chunk[\"HGNC ID\"].isna()) \n",
    "        chunk[\"HGNC ID\"] = chunk[\"HGNC ID\"].astype(int)\n",
    "        chunk = chunk[[\"HGNC ID\", \"ID_sample\", 'FATHMM prediction', \n",
    "                       \"Primary site\", 'Site subtype 1', 'Site subtype 2', 'Site subtype 3',\n",
    "                       'Primary histology', 'Histology subtype 1', 'Histology subtype 2',\n",
    "                       'Histology subtype 3']]\n",
    "\n",
    "        if i==0:\n",
    "            writer.writerow(chunk.columns.values)\n",
    "        for r in chunk.values:\n",
    "            writer.writerow(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second pass over the dataset: remove hypermutated samples (>1000 mutations)\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered_tmp.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=100000)\n",
    "\n",
    "sample_id_counter = Counter()\n",
    "for i, chunk in tqdm(enumerate(df)):\n",
    "    sample_id_counter.update(chunk[\"ID_sample\"][~chunk[\"ID_sample\"].isna()].values)\n",
    "hypermutated_samples = [s for s, v in sample_id_counter.items() if v>1000]\n",
    "\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered_tmp.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=100000)\n",
    "with open(\"tmp_data/cosmic_filtered_tmp2.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i, chunk in tqdm(enumerate(df)):\n",
    "        chunk = chunk[(~chunk[\"ID_sample\"].isin(hypermutated_samples))]        \n",
    "        if i==0:\n",
    "            writer.writerow(chunk.columns.values)\n",
    "        for r in chunk.values:\n",
    "            writer.writerow(r)\n",
    "\n",
    "# Third pass over the dataset: remove underrepresented genes (<100 occurrences)\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered_tmp2.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=100000)\n",
    "gene_id_counter = Counter()\n",
    "for i, chunk in tqdm(enumerate(df)):\n",
    "    gene_id_counter.update(chunk[\"HGNC ID\"][~chunk[\"HGNC ID\"].isna()].values) \n",
    "low_count_genes = [g for g, v in gene_id_counter.items() if v<100]\n",
    "\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered_tmp2.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=100000)\n",
    "with open(\"tmp_data/cosmic_filtered.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i, chunk in tqdm(enumerate(df)):\n",
    "        chunk = chunk[(~chunk[\"HGNC ID\"].isin(low_count_genes))]        \n",
    "        if i==0:\n",
    "            writer.writerow(chunk.columns.values)\n",
    "        for r in chunk.values:\n",
    "            writer.writerow(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the filtered data into the relevant portions for the encoding of the mutations and the subtypes\n",
    "# with this methods both can fit into memory without streaming\n",
    "\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=100000)\n",
    "with open(\"tmp_data/cosmic_filtered_subtype.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i, chunk in tqdm(enumerate(df)):\n",
    "        \n",
    "        chunk = chunk[[\"ID_sample\", \"Primary site\", 'Site subtype 1', 'Site subtype 2', 'Site subtype 3',\n",
    "       'Primary histology', 'Histology subtype 1', 'Histology subtype 2',\n",
    "       'Histology subtype 3']]\n",
    "        \n",
    "        if i==0:\n",
    "            writer.writerow(chunk.columns.values)\n",
    "        for r in chunk.values:\n",
    "            writer.writerow(r)\n",
    "            \n",
    "df = pd.read_csv('tmp_data/cosmic_filtered.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=100000)\n",
    "with open(\"tmp_data/cosmic_filtered_mutation_data.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i, chunk in tqdm(enumerate(df)):\n",
    "        \n",
    "        chunk = chunk[[\"HGNC ID\", \"ID_sample\", 'FATHMM prediction']]\n",
    "        \n",
    "        if i==0:\n",
    "            writer.writerow(chunk.columns.values)\n",
    "        for r in chunk.values:\n",
    "            writer.writerow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and saving each sample based on its site and histology subtype. The encoding is a binary vector where a 1 in component j represents that \n",
    "# the sample belongs to the subtype j, and 0 signals otherwise. The ordering of the subtypes is found in the disease_ontology module, and \n",
    "# the result of the processing is a numpy matrix where the ordering of the rows corresponds to the sorted ids found in \"sample_ids.json\"\n",
    "\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered_subtype.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "df = df.drop_duplicates(subset=['ID_sample'])\n",
    "\n",
    "sample_ids = []\n",
    "encodings = []\n",
    "for i, (id_sample, row) in enumerate(zip(df.values[:,0], df.values[:,1:])):\n",
    "    hist_subtype = map_histological_subtype(*row)\n",
    "    site_subtype = map_site_subtype(*row)    \n",
    "    encoding = np.array(categorical_encoding(site_subtype, hist_subtype))\n",
    "    if np.sum(encoding)>0:\n",
    "        if np.sum(encoding[-2:])>1:\n",
    "            print(i)\n",
    "        encodings.append(encoding)\n",
    "        sample_ids.append(id_sample)\n",
    "        \n",
    "encodings = np.array(encodings)\n",
    "\n",
    "with open(\"data/sample_ids.json\", \"w\") as f:\n",
    "    json.dump(sample_ids, f)\n",
    "np.save(\"data/sample_encodings.npy\", encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the samples IDs to the corresponding mutated genes. Mutations set is a lookup table where each sample ID corresponds to two lists. The first includes\n",
    "# the deleterious mutations, while the second groups non-deleterious mutations. The split is based on the FATHMM prediction included in the dataset.\n",
    "# The file sorted_mutations.json gives a unique ordering for the mutated genes that will be used\n",
    "# for the binary encoding of the mutation profile of each sample.\n",
    "\n",
    "mutations_set = {s: ([], []) for s in sample_ids}\n",
    "df = pd.read_csv('tmp_data/cosmic_filtered_mutation_data.csv', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    if row[\"ID_sample\"] in mutations_set.keys():\n",
    "        if row[\"FATHMM prediction\"] == \"PATHOGENIC\":\n",
    "            mutations_set[row[\"ID_sample\"]][0].append(int(row[\"HGNC ID\"]))\n",
    "        else:\n",
    "            mutations_set[row[\"ID_sample\"]][1].append(int(row[\"HGNC ID\"]))\n",
    "        \n",
    "with open(\"data/mutations_mapping_split.json\", \"w\") as f:\n",
    "    json.dump(mutations_set, f, indent=2)\n",
    "    \n",
    "sorted_mutations = set()\n",
    "for k, v in mutations_set.items():\n",
    "    sorted_mutations.update(v[0])\n",
    "    sorted_mutations.update(v[1])\n",
    "    \n",
    "sorted_mutations = sorted(list(sorted_mutations))\n",
    "with open(\"data/sorted_mutations.json\", \"w\") as f:\n",
    "    json.dump(sorted_mutations, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the temporary files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
